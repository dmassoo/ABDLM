version: "3.7"
services:
  my-generator:
    build: ./generator
    # Do we need links?
    links:
      - my-kafka
    command: bash -c "python producer.py"
    # https://stackoverflow.com/questions/36249744/interactive-shell-using-docker-compose
    stdin_open: true # docker run -i
    tty: true        # docker run -t
    volumes:
      - ./generator/code:/code
    environment:
      - KAFKA_CLUSTERS_0_BOOTSTRAP_SERVERS=kafka:9092
      - KAFKA_CLUSTERS_0_NAME=kraft
    image: vandosik/generator:latest
    depends_on:
     - my-kafka
  my-kafka:
    image: 'bitnami/kafka:latest'
    environment:
      - KAFKA_ENABLE_KRAFT=yes
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://my-kafka:9092
      - KAFKA_CFG_BROKER_ID=1
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@my-kafka:9093
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_KRAFT_CLUSTER_ID=L0ZEQh1yTbGhNNUE7-6wSQ
    # volumes:
    #   - ./kafka:/bitnami/kafka
    volumes:
      - /bitnami/kafka
    ports:
      - "9092:9092"
      - "9093:9093"
  my-ui:
    image: provectuslabs/kafka-ui:v0.4.0
    ports:
      - "9090:8080"
    environment:
      - KAFKA_CLUSTERS_0_BOOTSTRAP_SERVERS=my-kafka:9092
      - KAFKA_CLUSTERS_0_NAME=kraft
    depends_on:
     - my-kafka
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.2'
          memory: 256M
  my-cassandra:
    image: cassandra:latest
    volumes:
      - ./cassandra:/cassandra
      - /var/lib/cassandra
    ports:
      - "9042:9042"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 5000M
        reservations:
          cpus: '0.5'
          memory: 4000M
  my-spark-master:
    image: bitnami/spark:latest
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - '8080:8080'
      - '7077:7077'
  my-spark-worker:
    image: bitnami/spark:latest
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://my-spark-master:7077
      - SPARK_WORKER_MEMORY=3G
      - SPARK_WORKER_CORES=3
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    deploy:
      mode: replicated
      replicas: 2
    # ports:
    # - '8081:8081'
  my-spark-client:
    build: ./spark
    image: vandosik/spark-client:latest
    command: bash -c /sh/submit_archiving.sh
    volumes:
      - ./spark/code:/code
      - ./spark/sh:/sh
    links:
      - my-spark-master
      - my-kafka
      - my-cassandra
    depends_on:
      - my-spark-master
      - my-kafka
      - my-cassandra
    deploy:
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 1
        window: 60s
  # jupyter-notebook:
  #   ports:
  #     - '8888:8888'
  #   image: jupyter/pyspark-notebook:latest
  #   networks:
  #     - my-network
  #   links:
  #     - my-spark-master
  #   deploy:
  #     restart_policy:
  #       condition: on-failure
  #       delay: 5s
  #       max_attempts: 3
  #       window: 60s
  #     resources:
  #       limits:
  #         cpus: '0.5'
  #         memory: 512M
  #       reservations:
  #         cpus: '0.2'
  #         memory: 256M
  grafana:
    build: ./grafana
    image: vandosik/grafana:latest
    ports:
      - "3000:3000"
    environment:
      GF_LOG_LEVEL: debug
      GF_PLUGINS_ALLOW_LOADING_UNSIGNED_PLUGINS: hadesarchitect-cassandra-datasource
    # volumes:
    #   - ./grafana:/var/lib/grafana
    volumes:
      - /var/lib/grafana
    depends_on:
      - my-cassandra

  minio:
    image: minio/minio
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_storage:/data
    environment:
      MINIO_ROOT_USER: adminsdf
      MINIO_ROOT_PASSWORD: adminsdf
    command: server --console-address ":9001" /data

volumes:
  minio_storage: {}