version: "3.7"
networks:
  my-network:
    driver: bridge

# Settings and configurations that are common for all containers
x-minio-common: &minio-common
  image: quay.io/minio/minio:RELEASE.2022-12-02T19-19-22Z
  command: server --console-address ":9001" http://minio{1...4}/data{1...2}
  expose:
    - "9000"
    - "9001"
  # environment:
    # MINIO_ROOT_USER: minioadmin
    # MINIO_ROOT_PASSWORD: minioadmin
  healthcheck:
    test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
    interval: 30s
    timeout: 20s
    retries: 3
    
services:
  my-generator:
    build: ./generator
    # Do we need links?
    links:
      - my-kafka
    command: bash -c "python producer.py"
    # https://stackoverflow.com/questions/36249744/interactive-shell-using-docker-compose
    stdin_open: true # docker run -i
    tty: true        # docker run -t
    volumes:
      - ./generator/code:/code
    environment:
      - KAFKA_CLUSTERS_0_BOOTSTRAP_SERVERS=kafka:9092
      - KAFKA_CLUSTERS_0_NAME=kraft
    networks:
      - my-network
    image: vandosik/generator:latest
    depends_on:
     - my-kafka
  my-kafka:
    image: 'bitnami/kafka:latest'
    environment:
      - KAFKA_ENABLE_KRAFT=yes
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://my-kafka:9092
      - KAFKA_CFG_BROKER_ID=1
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@my-kafka:9093
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_KRAFT_CLUSTER_ID=L0ZEQh1yTbGhNNUE7-6wSQ
    # volumes:
    #   - ./kafka:/bitnami/kafka
    volumes:
      - /bitnami/kafka
    ports:
      - "9092:9092"
      - "9093:9093"
    networks:
      - my-network
  my-ui:
    image: provectuslabs/kafka-ui:v0.4.0
    ports:
      - "9090:8080"
    environment:
      - KAFKA_CLUSTERS_0_BOOTSTRAP_SERVERS=my-kafka:9092
      - KAFKA_CLUSTERS_0_NAME=kraft
    networks:
      - my-network
    depends_on:
     - my-kafka
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.2'
          memory: 256M
  my-cassandra:
    image: cassandra:latest
    volumes:
      - ./cassandra:/cassandra
      - /var/lib/cassandra
    networks:
      - my-network
    ports:
      - "9042:9042"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 5000M
        reservations:
          cpus: '0.5'
          memory: 4000M
  my-spark-master:
    image: bitnami/spark:latest
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - '8080:8080'
      - '7077:7077'
    networks:
      - my-network
  my-spark-worker:
    image: bitnami/spark:latest
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://my-spark-master:7077
      - SPARK_WORKER_MEMORY=3G
      - SPARK_WORKER_CORES=3
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    networks:
      - my-network
    deploy:
      mode: replicated
      replicas: 2
    # ports:
    # - '8081:8081'
  my-spark-client:
    build: ./spark
    image: vandosik/spark-client:latest
    command: bash -c /sh/start_listeners.sh
    networks:
      - my-network
    volumes:
      - ./spark/code:/code
      - ./spark/sh:/sh
      - ./spark/archiving:/archiving
    links:
      - my-spark-master
      - my-kafka
      - my-cassandra
    depends_on:
      - my-spark-master
      - my-kafka
      - my-cassandra
    deploy:
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 1
        window: 60s
  # jupyter-notebook:
  #   ports:
  #     - '8888:8888'
  #   image: jupyter/pyspark-notebook:latest
  #   networks:
  #     - my-network
  #   links:
  #     - my-spark-master
  #   deploy:
  #     restart_policy:
  #       condition: on-failure
  #       delay: 5s
  #       max_attempts: 3
  #       window: 60s
  #     resources:
  #       limits:
  #         cpus: '0.5'
  #         memory: 512M
  #       reservations:
  #         cpus: '0.2'
  #         memory: 256M
  grafana:
    build: ./grafana
    image: vandosik/grafana:latest
    ports:
      - "3000:3000"
    environment:
      GF_LOG_LEVEL: debug
      GF_PLUGINS_ALLOW_LOADING_UNSIGNED_PLUGINS: hadesarchitect-cassandra-datasource
    # volumes:
    #   - ./grafana:/var/lib/grafana
    volumes:
      - /var/lib/grafana
    networks:
      - my-network
    depends_on:
      - my-cassandra






# starts 4 docker containers running minio server instances.
# using nginx reverse proxy, load balancing, you can access
# it through port 9000.
  minio1:
    <<: *minio-common
    hostname: minio1
    volumes:
      - data1-1:/data1
      - data1-2:/data2

  minio2:
    <<: *minio-common
    hostname: minio2
    volumes:
      - data2-1:/data1
      - data2-2:/data2

  minio3:
    <<: *minio-common
    hostname: minio3
    volumes:
      - data3-1:/data1
      - data3-2:/data2

  minio4:
    <<: *minio-common
    hostname: minio4
    volumes:
      - data4-1:/data1
      - data4-2:/data2

  nginx:
    image: nginx:1.19.2-alpine
    hostname: nginx
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    ports:
      - "9000:9000"
      - "9001:9001"
    depends_on:
      - minio1
      - minio2
      - minio3
      - minio4

## By default this config uses default local driver,
## For custom volumes replace with volume driver configuration.
volumes:
  data1-1:
  data1-2:
  data2-1:
  data2-2:
  data3-1:
  data3-2:
  data4-1:
  data4-2: