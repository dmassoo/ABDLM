{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy.random import choice, randint\n",
    "import uuid\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Формат представления данных\n",
    "#\n",
    "# logs = {\n",
    "#     \"timestamp\": \"DateTime\",\n",
    "#     \"level\": \"TRACE/DEBUG/.../ERROR\",\n",
    "#     \"microservice_id\": \"String\",\n",
    "#     \"operation_type\": \"VIEW/BUY/CANCEL/REFUND\",\n",
    "#     \"operation_id\": \"UUID\",\n",
    "#     \"user_id\": \"UUID\",\n",
    "#     \"message\": \"Arbitrary string\"\n",
    "# }\n",
    "#\n",
    "# metrics = {\n",
    "#     \"timestamp\": \"DateTime\",\n",
    "#     \"microservice_id\": \"String\",\n",
    "#     \"operation_type\": \"GET/POST or view,buy,cancel,refund\",\n",
    "#     \"operation_id\": \"UUID\",\n",
    "#     \"user_id\": \"UUID\",\n",
    "#     \"value\": \"Arbitrary value\"  #exec time, cpu/gpu consumption, retry count\n",
    "# }\n",
    "EVENT_TYPE = ['VIEW', 'TRANSACTION', 'CPU', 'RAM']\n",
    "MICROSERVICE_ID = ['VIEW', 'BUY', 'CANCEL', 'REFUND']\n",
    "LEVEL = ['TRACE', 'DEBUG', 'ERROR']\n",
    "OPERATION_TYPE = MICROSERVICE_ID\n",
    "OPERATION_TYPE.append('GET')\n",
    "OPERATION_TYPE.append('POST')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 76928.65it/s]\n"
     ]
    }
   ],
   "source": [
    "simultaneous_users = 12\n",
    "average_time_in_site = 6 #sec\n",
    "potencial_users = 1000\n",
    "\n",
    "potential_operation_id = 100\n",
    "simultaneous_operation_id = 3\n",
    "\n",
    "user_db = []\n",
    "for user_id in tqdm(range(potencial_users)):\n",
    "    user_db.append(str(uuid.uuid4()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# def common_metrics(start,simultaneous_users=simultaneous_users, average_time_in_site=average_time_in_site):\n",
    "#     users = []\n",
    "#     metrics = {}\n",
    "#     dt_now=datetime.now().replace(tzinfo=timezone.utc).timestamp()\n",
    "#     if  (dt_now - start) > average_time_in_site or not users:\n",
    "#         users = choice(user_db, simultaneous_users)\n",
    "#         start = datetime.now().replace(tzinfo=timezone.utc).timestamp()\n",
    "#     metrics['timestamp'] = dt_now\n",
    "#     metrics['microservice_id'] = choice(MICROSERVICE_ID)\n",
    "#     metrics['operation_id'] = str(uuid.uuid4())\n",
    "#     metrics['user_id'] = choice(users)\n",
    "#     metrics['event_type'] = choice(EVENT_TYPE)\n",
    "#\n",
    "#     def generate_metrics_value():\n",
    "#         return 1\n",
    "#\n",
    "#     metrics['value'] = generate_metrics_value()\n",
    "#     return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# запускать многопоточно\n",
    "new = []\n",
    "def common_metrics_per_one():\n",
    "    user_metrics = []\n",
    "    operation_ids = [str(uuid.uuid4()) for _ in range (3)]\n",
    "    user = choice(user_db)\n",
    "    for i in range(randint(1, 30)):\n",
    "        metrics = {}\n",
    "        dt_now=datetime.now().replace(tzinfo=timezone.utc).timestamp()\n",
    "        metrics['timestamp'] = dt_now\n",
    "        metrics['microservice_id'] = choice(MICROSERVICE_ID)\n",
    "        metrics['operation_id'] = choice(operation_ids)\n",
    "        metrics['user_id'] = user\n",
    "        metrics['event_type'] = choice(EVENT_TYPE)\n",
    "\n",
    "        def generate_metrics_value():\n",
    "            return 1\n",
    "\n",
    "        metrics['value'] = generate_metrics_value()\n",
    "        user_metrics.append(metrics)\n",
    "    return user_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=12)(delayed(common_metrics_per_one)(user) for user in users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "def driver_func():\n",
    "    PROCESSES = 5\n",
    "    with multiprocessing.Pool(PROCESSES) as pool:\n",
    "        users = choice(user_db, 50)\n",
    "        results = [pool.apply_async(common_metrics_per_one, user) for user in users]\n",
    "\n",
    "        for r in results:\n",
    "            print('\\t', r.get())\n",
    "driver_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "def double(a):\n",
    "    return a * 2\n",
    "\n",
    "def driver_func():\n",
    "    PROCESSES = 4\n",
    "    with multiprocessing.Pool(PROCESSES) as pool:\n",
    "        params = [(1, ), (2, ), (3, ), (4, )]\n",
    "        results = [pool.apply_async(double, p) for p in params]\n",
    "\n",
    "        for r in results:\n",
    "            print('\\t', r.get())\n",
    "\n",
    "driver_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 142843.17it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy.random import choice, randint\n",
    "import uuid\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from types import FunctionType\n",
    "import marshal\n",
    "\n",
    "\n",
    "EVENT_TYPE = ['VIEW', 'TRANSACTION', 'CPU', 'RAM']\n",
    "MICROSERVICE_ID = ['VIEW', 'BUY', 'CANCEL', 'REFUND']\n",
    "LEVEL = ['TRACE', 'DEBUG', 'ERROR']\n",
    "OPERATION_TYPE = MICROSERVICE_ID\n",
    "OPERATION_TYPE.append('GET')\n",
    "OPERATION_TYPE.append('POST')\n",
    "\n",
    "simultaneous_users = 12\n",
    "average_time_in_site = 6 #sec\n",
    "potencial_users = 1000\n",
    "\n",
    "potential_operation_id = 100\n",
    "simultaneous_operation_id = 3\n",
    "\n",
    "user_db = []\n",
    "for user_id in tqdm(range(potencial_users)):\n",
    "    user_db.append(str(uuid.uuid4()))\n",
    "\n",
    "def common_metrics_per_one(user):\n",
    "    user_metrics = []\n",
    "    operation_ids = [str(uuid.uuid4()) for _ in range (3)]\n",
    "    # user = choice(user_db)\n",
    "    for i in range(randint(1, 30)):\n",
    "        metrics = {}\n",
    "        dt_now=datetime.now().replace(tzinfo=timezone.utc).timestamp()\n",
    "        metrics['timestamp'] = dt_now\n",
    "        metrics['microservice_id'] = choice(MICROSERVICE_ID)\n",
    "        metrics['operation_id'] = choice(operation_ids)\n",
    "        metrics['user_id'] = user\n",
    "        metrics['event_type'] = choice(EVENT_TYPE)\n",
    "\n",
    "        def generate_metrics_value():\n",
    "            return 1\n",
    "\n",
    "        metrics['value'] = generate_metrics_value()\n",
    "        user_metrics.append(metrics)\n",
    "    return user_metrics\n",
    "\n",
    "def driver_func():\n",
    "    PROCESSES = 5\n",
    "    with multiprocessing.Pool(PROCESSES) as pool:\n",
    "        users = choice(user_db, 50)\n",
    "        results = [pool.apply_async(common_metrics_per_one, user) for user in users]\n",
    "    return results\n",
    "def _applicable(*args, **kwargs):\n",
    "    name = kwargs['__pw_name']\n",
    "    code = marshal.loads(kwargs['__pw_code'])\n",
    "    gbls = globals() #gbls = marshal.loads(kwargs['__pw_gbls'])\n",
    "    defs = marshal.loads(kwargs['__pw_defs'])\n",
    "    clsr = marshal.loads(kwargs['__pw_clsr'])\n",
    "    fdct = marshal.loads(kwargs['__pw_fdct'])\n",
    "    func = FunctionType(code, gbls, name, defs, clsr)\n",
    "    func.fdct = fdct\n",
    "    del kwargs['__pw_name']\n",
    "    del kwargs['__pw_code']\n",
    "    del kwargs['__pw_defs']\n",
    "    del kwargs['__pw_clsr']\n",
    "    del kwargs['__pw_fdct']\n",
    "    return func(*args, **kwargs)\n",
    "\n",
    "def make_applicable(f, *args, **kwargs):\n",
    "    if not isinstance(f, FunctionType): raise ValueError('argument must be a function')\n",
    "    kwargs['__pw_name'] = f.__name__  # edited\n",
    "    kwargs['__pw_code'] = marshal.dumps(f.__code__)   # edited\n",
    "    kwargs['__pw_defs'] = marshal.dumps(f.__defaults__)  # edited\n",
    "    kwargs['__pw_clsr'] = marshal.dumps(f.__closure__)  # edited\n",
    "    kwargs['__pw_fdct'] = marshal.dumps(f.__dict__)   # edited\n",
    "    return _applicable, args, kwargs\n",
    "\n",
    "def _mappable(x):\n",
    "    x,name,code,defs,clsr,fdct = x\n",
    "    code = marshal.loads(code)\n",
    "    gbls = globals() #gbls = marshal.loads(gbls)\n",
    "    defs = marshal.loads(defs)\n",
    "    clsr = marshal.loads(clsr)\n",
    "    fdct = marshal.loads(fdct)\n",
    "    func = FunctionType(code, gbls, name, defs, clsr)\n",
    "    func.fdct = fdct\n",
    "    return func(x)\n",
    "\n",
    "def make_mappable(f, iterable):\n",
    "    if not isinstance(f, FunctionType): raise ValueError('argument must be a function')\n",
    "    name = f.__name__    # edited\n",
    "    code = marshal.dumps(f.__code__)   # edited\n",
    "    defs = marshal.dumps(f.__defaults__)  # edited\n",
    "    clsr = marshal.dumps(f.__closure__)  # edited\n",
    "    fdct = marshal.dumps(f.__dict__)  # edited\n",
    "    return _mappable, ((i,name,code,defs,clsr,fdct) for i in iterable)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "TimeoutError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTimeoutError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[1;32mIn [7]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      3\u001B[0m pool    \u001B[38;5;241m=\u001B[39m Pool(processes\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m      4\u001B[0m results \u001B[38;5;241m=\u001B[39m [pool\u001B[38;5;241m.\u001B[39mapply_async(\u001B[38;5;241m*\u001B[39mmake_applicable(common_metrics_per_one, user)) \u001B[38;5;28;01mfor\u001B[39;00m user \u001B[38;5;129;01min\u001B[39;00m users]\n\u001B[1;32m----> 5\u001B[0m data \u001B[38;5;241m=\u001B[39m [result\u001B[38;5;241m.\u001B[39mget(timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m result \u001B[38;5;129;01min\u001B[39;00m results]\n",
      "Input \u001B[1;32mIn [7]\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m      3\u001B[0m pool    \u001B[38;5;241m=\u001B[39m Pool(processes\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m      4\u001B[0m results \u001B[38;5;241m=\u001B[39m [pool\u001B[38;5;241m.\u001B[39mapply_async(\u001B[38;5;241m*\u001B[39mmake_applicable(common_metrics_per_one, user)) \u001B[38;5;28;01mfor\u001B[39;00m user \u001B[38;5;129;01min\u001B[39;00m users]\n\u001B[1;32m----> 5\u001B[0m data \u001B[38;5;241m=\u001B[39m [\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m result \u001B[38;5;129;01min\u001B[39;00m results]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PycharmProjects\\lib\\multiprocessing\\pool.py:767\u001B[0m, in \u001B[0;36mApplyResult.get\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    765\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwait(timeout)\n\u001B[0;32m    766\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mready():\n\u001B[1;32m--> 767\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m\n\u001B[0;32m    768\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_success:\n\u001B[0;32m    769\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value\n",
      "\u001B[1;31mTimeoutError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    users = choice(user_db, 10)\n",
    "    pool    = Pool(processes=2)\n",
    "    results = [pool.apply_async(*make_applicable(common_metrics_per_one, user)) for user in users]\n",
    "    data = [result.get(timeout=10) for result in results]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "[<bound method ApplyResult.get of <multiprocessing.pool.ApplyResult object at 0x0000020A28BCEA60>>,\n <bound method ApplyResult.get of <multiprocessing.pool.ApplyResult object at 0x0000020A28BCEBB0>>,\n <bound method ApplyResult.get of <multiprocessing.pool.ApplyResult object at 0x0000020A28BCECD0>>,\n <bound method ApplyResult.get of <multiprocessing.pool.ApplyResult object at 0x0000020A28BCEDF0>>,\n <bound method ApplyResult.get of <multiprocessing.pool.ApplyResult object at 0x0000020A4147B400>>,\n <bound method ApplyResult.get of <multiprocessing.pool.ApplyResult object at 0x0000020A4147B760>>,\n <bound method ApplyResult.get of <multiprocessing.pool.ApplyResult object at 0x0000020A4147B850>>,\n <bound method ApplyResult.get of <multiprocessing.pool.ApplyResult object at 0x0000020A4147BA30>>,\n <bound method ApplyResult.get of <multiprocessing.pool.ApplyResult object at 0x0000020A4147BBE0>>,\n <bound method ApplyResult.get of <multiprocessing.pool.ApplyResult object at 0x0000020A4147BDF0>>]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}